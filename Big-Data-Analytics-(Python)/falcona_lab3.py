# -*- coding: utf-8 -*-
"""Falcona_Lab3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oGP6hI6xS0iYeHYsno5KWlAj3DzGUvC2
"""

# Commented out IPython magic to ensure Python compatibility.
# Matt Falcona Week 9 / Lab 3

# importing packages based on MLP Walk through example code

from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
from keras.utils import np_utils

import os
import struct
import numpy as np
import pandas
import tensorflow as tf

import time
import matplotlib.pyplot as plt
# %matplotlib inline

# Commented out IPython magic to ensure Python compatibility.
# defining load_mnist function from https://github.com/zalandoresearch/fashion-mnist link found in Lab description

def load_mnist(path, kind='train'):
    import os
    import gzip
    import numpy as np

    """Load MNIST data from `path`"""
    labels_path = os.path.join(path,
                               '%s-labels-idx1-ubyte.gz'
#                                % kind)
    images_path = os.path.join(path,
                               '%s-images-idx3-ubyte.gz'
#                                % kind)

    with gzip.open(labels_path, 'rb') as lbpath:
        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,
                               offset=8)

    with gzip.open(images_path, 'rb') as imgpath:
        images = np.frombuffer(imgpath.read(), dtype=np.uint8,
                               offset=16).reshape(len(labels), 784)

    return images, labels

# loading data using tensorflow and keras

tf.keras.datasets.fashion_mnist.load_data()

# defining train and test sets

(X_train, y_train), (X_test, y_test) = mnist.load_data()

# flattening 28 x 28 image to 784 vector
num_pixels = X_train.shape[1] * X_train.shape[2]
X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')
X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')

# normalizing inputs from rgb color to 0-1
X_train = X_train / 255
X_test = X_test / 255

# shuffling training sequence using random sequence from numpy

shuffle_index = np.random.permutation(60000)
X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]

# shape of training set

print('Rows: %d, columns: %d' % (X_train.shape[0], X_train.shape[1]))

# shape of test set

print('Rows: %d, columns: %d' % (X_test.shape[0], X_test.shape[1]))

# modeling - random forest

from sklearn.ensemble import RandomForestClassifier

import time
start_time = time.time()
forest = RandomForestClassifier(n_estimators = 100)
print("Execution Time: %s seconds" % (time.time() - start_time))

# random forest compute time and score

start_time = time.time()
forest.fit(X_train, y_train)
print("Execution Time: %s seconds" % (time.time() - start_time))
print('Score: ', forest.score(X_train, y_train))
print('Score: ', forest.score(X_test, y_test))

# random forest prediction
start_time = time.time()
predictions = forest.predict(X_test)
print("Execution Time: %s seconds" % (time.time() - start_time))

# modeling - MLP classifier

from sklearn.neural_network import MLPClassifier
start_time = time.time()

mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, alpha=.01, solver="adam", verbose = 10, tol=.000001, random_state=1, learning_rate_init=.001)
print("Execution Time: %s seconds" % (time.time() - start_time))

# model fit
start_time = time.time()

mlp.fit(X_train,y_train)
print("Execution Time: %s seconds" % (time.time() - start_time))

# neural network compute time and score

start_time = time.time()
print("Execution Time: %s seconds" % (time.time() - start_time))
print("Training set score: {0}".format(mlp.score(X_train, y_train)))
print()
print("Test set score: {0}".format(mlp.score(X_test, y_test)))

# -*- coding: utf-8 -*-
"""IST718_Final_Project_NN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MK0uMFiNuM5j6qEyCuGqa54cQ-k5hdiW
"""

# neural network code for IST718 Final Project

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras import utils
from tensorflow.keras import backend as K
K.image_data_format()

from tensorflow.keras import layers
from tensorflow.keras.layers.experimental import preprocessing

from sklearn.model_selection import train_test_split

import matplotlib.pyplot as plt
import time

import pandas as pd
import numpy as np

data = pd.read_csv('/pub_Hs_lean.csv')

data.head()

data.info()
data.shape

tf_data = tf.data.experimental.make_csv_dataset(
    '/pub_Hs_lean.csv',
    batch_size = 400,
    num_epochs = 40,
)

model_data = data.drop(columns=['District','NCES_ID'])

model_data.head()

y = model_data.PURCHASED
x = model_data.drop('PURCHASED', axis = 1)

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)

def base_model():
    model = Sequential()
    model.add(Dense(7, kernel_initializer='normal',activation='relu'))
    model.add(Dropout(.35))
    model.add(Dense(1, kernel_initializer='normal',activation='sigmoid')) # sigmoid == logistic for binary output
    model.compile(loss='binary_crossentropy', optimizer = 'adam',metrics=['accuracy'])
    return(model)

start = time.time()  # TRACK TIME

model = base_model()
history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=40, batch_size=400, verbose=2)

# MODEL - RESULTS

scores = model.evaluate(x_test, y_test, verbose=0)
print("Baseline Error: %.2f%%" % (100-scores[1]*100))

end = time.time()
final_time = end-start
print(final_time)

print(model.summary())

def plot_train_curve(history):
    colors = ['#e66101','#fdb863','#b2abd2','#5e3c99']
    accuracy = history.history['accuracy']
    val_accuracy = history.history['val_accuracy']
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    epochs = range(len(accuracy))
    with plt.style.context("ggplot"):
        plt.figure(figsize=(8, 8/1.618))
        plt.plot(epochs, accuracy, marker='o', c=colors[3], label='Training accuracy')
        plt.plot(epochs, val_accuracy, c=colors[0], label='Validation accuracy')
        plt.title('Training and validation accuracy')
        plt.legend()
        plt.figure(figsize=(8, 8/1.618))
        plt.plot(epochs, loss, marker='o', c=colors[3], label='Training loss')
        plt.plot(epochs, val_loss, c=colors[0], label='Validation loss')
        plt.title('Training and validation loss')
        plt.legend()
        plt.show()

plot_train_curve(history)
